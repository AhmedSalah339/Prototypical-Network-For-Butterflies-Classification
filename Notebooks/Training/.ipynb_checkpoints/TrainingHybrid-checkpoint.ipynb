{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "-n_jxtPg8vHw"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "import glob\n",
    "import argparse\n",
    "import os\n",
    "import argparse\n",
    "\n",
    "import numpy as np\n",
    "import pickle\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "E:\\CVprojects\\Butterflies\n"
     ]
    }
   ],
   "source": [
    "cd ..\\.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "Sp-0DYPBdObg"
   },
   "outputs": [],
   "source": [
    "# !git clone https://github.com/orobix/Prototypical-Networks-for-Few-shot-Learning-PyTorch.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "cs5zOAtqfObz"
   },
   "outputs": [],
   "source": [
    "def load_dict(filename_):\n",
    "    with open(filename_, 'rb') as f:\n",
    "        ret_di = pickle.load(f)\n",
    "    return ret_di\n",
    "def save_dict(di_, filename_):\n",
    "    with open(filename_, 'wb') as f:\n",
    "        pickle.dump(di_, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "Qc_6QHkLdq_B"
   },
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'get_parser' from 'src.Prototypical_Networks_for_Few_shot_Learning_PyTorch.src.parser_util' (E:\\CVprojects\\Butterflies\\src\\Prototypical_Networks_for_Few_shot_Learning_PyTorch\\src\\parser_util.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_138220\\402125704.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msrc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mPrototypical_Networks_for_Few_shot_Learning_PyTorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msrc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprototypical_loss\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mprototypical_loss\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mloss_fn\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msrc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mPrototypical_Networks_for_Few_shot_Learning_PyTorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msrc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprotonet\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mProtoNet\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0msrc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mPrototypical_Networks_for_Few_shot_Learning_PyTorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msrc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparser_util\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mget_parser\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m: cannot import name 'get_parser' from 'src.Prototypical_Networks_for_Few_shot_Learning_PyTorch.src.parser_util' (E:\\CVprojects\\Butterflies\\src\\Prototypical_Networks_for_Few_shot_Learning_PyTorch\\src\\parser_util.py)"
     ]
    }
   ],
   "source": [
    "from src.Prototypical_Networks_for_Few_shot_Learning_PyTorch.src.prototypical_batch_sampler import PrototypicalBatchSampler\n",
    "from src.Prototypical_Networks_for_Few_shot_Learning_PyTorch.src.prototypical_loss import prototypical_loss as loss_fn\n",
    "from src.Prototypical_Networks_for_Few_shot_Learning_PyTorch.src.protonet import ProtoNet\n",
    "from src.Prototypical_Networks_for_Few_shot_Learning_PyTorch.src.parser_util import get_parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "wakXeTm7DsXQ"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Dataset' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_138220\\984288121.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mclass\u001b[0m \u001b[0mButterfly200DataSet\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mDataset\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0msplit_dict_path\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mprecashe\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mmode\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'train'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m         \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mButterfly200DataSet\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m         \u001b[0msplit_dict\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mload_dict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msplit_dict_path\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpaths\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msplit_dict\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mmode\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'Dataset' is not defined"
     ]
    }
   ],
   "source": [
    "class Butterfly200DataSet(Dataset):\n",
    "    def __init__(self,split_dict_path,precashe=True,mode='train'):\n",
    "        super(Butterfly200DataSet, self).__init__()\n",
    "        split_dict = load_dict(split_dict_path)\n",
    "        self.paths = split_dict[mode]\n",
    "        self.images_classes = {}\n",
    "        self.y = []\n",
    "\n",
    "\n",
    "        for path in self.paths:\n",
    "            cls = int(os.path.basename(path.split('.')[0]))-1\n",
    "            if cls not in self.images_classes:\n",
    "                self.images_classes[cls] = []\n",
    "            self.images_classes[cls].append(path)\n",
    "            self.y.append(cls)\n",
    "#         np.random.shuffle(self.y)\n",
    "        classes = np.unique(self.y)\n",
    "        self.map = {i:cls for i,cls in enumerate(classes)}\n",
    "        map2 = {cls:i for i,cls in enumerate(classes)}\n",
    "        self.y = [map2[e] for e in self.y]\n",
    "        self.imgs_cashe = {}\n",
    "        if precashe:\n",
    "            for i in tqdm(range(len(self.paths))):\n",
    "                img = self.load_img(self.paths[i])\n",
    "                label = self.y[i]\n",
    "                self.imgs_cashe[i] = (img,label)\n",
    "    def load_img(self,path):\n",
    "        x = torch.load(path)\n",
    "        return x\n",
    "    def __getitem__(self, index):\n",
    "        if  index in self.imgs_cashe:\n",
    "            return self.imgs_cashe[index][0].cuda(non_blocking=True),self.imgs_cashe[index][1]\n",
    "        else:\n",
    "            img = self.load_img(self.paths[index])\n",
    "            img = img.cuda(non_blocking=True)\n",
    "            label = self.y[index]\n",
    "        return img,label\n",
    "    def __len__(self):\n",
    "        return len(self.paths)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ACqMJh-0lsyA",
    "outputId": "55df6364-39ca-4113-aab9-dd366e449edc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "E:\\CVprojects\\Butterflies\n"
     ]
    }
   ],
   "source": [
    "cd E:\\CVprojects\\Butterflies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 36
    },
    "id": "SO3lhVl4WG_s",
    "outputId": "0ed36c04-9a5f-45df-ff64-6bd5068c301a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'E:\\\\CVprojects\\\\Butterflies\\\\split_dict_sub_main_clust.pkl'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "split_dict_name = \"split_dict_sub_main_clust.pkl\"\n",
    "# split_dict_name = \"split_dict_sub.pkl\"\n",
    "split_dict_path = os.path.join(os.getcwd(),split_dict_name)\n",
    "split_dict_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "ozxW_VuLPidn"
   },
   "outputs": [],
   "source": [
    "split_dict = load_dict(split_dict_path)\n",
    "paths = split_dict['train']\n",
    "images_classes = {}\n",
    "for path in paths:\n",
    "    cls = int(os.path.basename(path.split('.')[0]))-1\n",
    "    if cls not in images_classes:\n",
    "        images_classes[cls] = []\n",
    "    images_classes[cls].append(path)\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "IweojItJPtgY",
    "outputId": "060e41aa-d853-45e4-bd50-a61a61c91556"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lens = []\n",
    "for key in images_classes:\n",
    "    lens.append(len(images_classes[key]))\n",
    "lens = np.array(lens)\n",
    "len(lens[lens<20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "-fSY3satgbSz"
   },
   "outputs": [],
   "source": [
    "def init_seed(opt):\n",
    "    torch.cuda.cudnn_enabled = True\n",
    "    np.random.seed(opt.manual_seed)\n",
    "    torch.manual_seed(opt.manual_seed)\n",
    "    torch.cuda.manual_seed(opt.manual_seed)\n",
    "def init_dataset(opt, mode):\n",
    "    dataset = Butterfly200DataSet(split_dict_path,mode=mode)\n",
    "    n_classes = len(np.unique(dataset.y))\n",
    "    if n_classes < opt.classes_per_it_tr or n_classes < opt.classes_per_it_val:\n",
    "        raise(Exception('There are not enough classes in the dataset in order ' +\n",
    "                        'to satisfy the chosen classes_per_it. Decrease the ' +\n",
    "                        'classes_per_it_{tr/val} option and try again.'))\n",
    "    return dataset\n",
    "\n",
    "\n",
    "def init_sampler(opt, labels, mode):\n",
    "    if 'train' in mode:\n",
    "        classes_per_it = opt.classes_per_it_tr\n",
    "        num_samples = opt.num_support_tr + opt.num_query_tr\n",
    "    else:\n",
    "        classes_per_it = opt.classes_per_it_val\n",
    "        num_samples = opt.num_support_val + opt.num_query_val\n",
    "\n",
    "    return PrototypicalBatchSampler(labels=labels,\n",
    "                                    classes_per_it=classes_per_it,\n",
    "                                    num_samples=num_samples,\n",
    "                                    iterations=opt.iterations)\n",
    "def init_dataloader(opt, mode):\n",
    "    dataset = init_dataset(opt, mode)\n",
    "    sampler = init_sampler(opt, dataset.y, mode)\n",
    "    dataloader = torch.utils.data.DataLoader(dataset, batch_sampler=sampler)\n",
    "    return dataloader\n",
    "def init_protonet(opt):\n",
    "    '''\n",
    "    Initialize the ProtoNet\n",
    "    '''\n",
    "    device = 'cuda:0' if torch.cuda.is_available() and opt.cuda else 'cpu'\n",
    "    model = ProtoNet(x_dim=128).to(device)\n",
    "    return model\n",
    "def init_optim(opt, model):\n",
    "    '''\n",
    "    Initialize optimizer\n",
    "    '''\n",
    "    return torch.optim.Adam(params=model.parameters(),\n",
    "                            lr=opt.learning_rate)\n",
    "def init_lr_scheduler(opt, optim):\n",
    "    '''\n",
    "    Initialize the learning rate scheduler\n",
    "    '''\n",
    "    return torch.optim.lr_scheduler.StepLR(optimizer=optim,\n",
    "                                           gamma=opt.lr_scheduler_gamma,\n",
    "                                           step_size=opt.lr_scheduler_step)\n",
    "def save_list_to_file(path, thelist):\n",
    "    with open(path, 'w') as f:\n",
    "        for item in thelist:\n",
    "            f.write(\"%s\\n\" % item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "aauYn7gvfeul"
   },
   "outputs": [],
   "source": [
    "def train(opt, tr_dataloader, model, optim, lr_scheduler, val_dataloader=None):\n",
    "    '''\n",
    "    Train the model with the prototypical learning algorithm\n",
    "    '''\n",
    "\n",
    "    device = 'cuda:0' if torch.cuda.is_available() and opt.cuda else 'cpu'\n",
    "\n",
    "    if val_dataloader is None:\n",
    "        best_state = None\n",
    "    train_loss = []\n",
    "    train_acc = []\n",
    "    val_loss = []\n",
    "    val_acc = []\n",
    "    best_acc = 0\n",
    "\n",
    "    best_model_path = os.path.join(opt.experiment_root, 'best_model.pth')\n",
    "    last_model_path = os.path.join(opt.experiment_root, 'last_model.pth')\n",
    "    for epoch in range(opt.epochs):\n",
    "        print('=== Epoch: {} ==='.format(epoch))\n",
    "        tr_iter = iter(tr_dataloader)\n",
    "        model.train()\n",
    "        \n",
    "        for batch in tqdm(tr_iter):\n",
    "            optim.zero_grad()\n",
    "            x, y = batch\n",
    "            x, y = x.to(device), y.to(device)\n",
    "#             emb_model(x)\n",
    "#             model_output = model(activation['layer2'])\n",
    "            model_output = model(x)\n",
    "            loss, acc = loss_fn(model_output, target=y,\n",
    "                                n_support=opt.num_support_tr)\n",
    "            loss.backward()\n",
    "            optim.step()\n",
    "            train_loss.append(loss.item())\n",
    "            train_acc.append(acc.item())\n",
    "            torch.cuda.empty_cache()\n",
    "        avg_loss = np.mean(train_loss[-opt.iterations:])\n",
    "        avg_acc = np.mean(train_acc[-opt.iterations:])\n",
    "        print('Avg Train Loss: {}, Avg Train Acc: {}'.format(avg_loss, avg_acc))\n",
    "        lr_scheduler.step()\n",
    "        if val_dataloader is None:\n",
    "            continue\n",
    "        val_iter = iter(val_dataloader)\n",
    "        model.eval()\n",
    "        for batch in tqdm(val_iter):\n",
    "            x, y = batch\n",
    "            x, y = x.to(device), y.to(device)\n",
    "#             emb_model(x)\n",
    "#             model_output = model(activation['layer2'])\n",
    "            model_output = model(x)\n",
    "            loss, acc = loss_fn(model_output, target=y,\n",
    "                                n_support=opt.num_support_val)\n",
    "            val_loss.append(loss.item())\n",
    "            val_acc.append(acc.item())\n",
    "            torch.cuda.empty_cache()\n",
    "        avg_loss = np.mean(val_loss[-opt.iterations:])\n",
    "        avg_acc = np.mean(val_acc[-opt.iterations:])\n",
    "        postfix = ' (Best)' if avg_acc >= best_acc else ' (Best: {})'.format(\n",
    "            best_acc)\n",
    "        print('Avg Val Loss: {}, Avg Val Acc: {}{}'.format(\n",
    "            avg_loss, avg_acc, postfix))\n",
    "        if avg_acc >= best_acc:\n",
    "            torch.save(model.state_dict(), best_model_path)\n",
    "            best_acc = avg_acc\n",
    "            best_state = model.state_dict()\n",
    "\n",
    "    torch.save(model.state_dict(), last_model_path)\n",
    "\n",
    "    for name in ['train_loss', 'train_acc', 'val_loss', 'val_acc']:\n",
    "        save_list_to_file(os.path.join(opt.experiment_root,\n",
    "                                       name + '.txt'), locals()[name])\n",
    "\n",
    "    return best_state, best_acc, train_loss, train_acc, val_loss, val_acc\n",
    "\n",
    "\n",
    "def test(opt, test_dataloader, model):\n",
    "    '''\n",
    "    Test the model trained with the prototypical learning algorithm\n",
    "    '''\n",
    "    device = 'cuda:0' if torch.cuda.is_available() and opt.cuda else 'cpu'\n",
    "    avg_acc = list()\n",
    "    for epoch in tqdm(range(opt.test_epochs)):\n",
    "        test_iter = iter(test_dataloader)\n",
    "        for batch in test_iter:\n",
    "            x, y = batch\n",
    "            x, y = x.to(device), y.to(device)\n",
    "            model_output = model(x)\n",
    "            _, acc = loss_fn(model_output, target=y,\n",
    "                             n_support=opt.num_support_val)\n",
    "            avg_acc.append(acc.item())\n",
    "    avg_acc = np.mean(avg_acc)\n",
    "    print('Test Acc: {}'.format(avg_acc))\n",
    "\n",
    "    return avg_acc\n",
    "\n",
    "\n",
    "def eval(opt):\n",
    "    '''\n",
    "    Initialize everything and train\n",
    "    '''\n",
    "    options = get_parser().parse_args()\n",
    "\n",
    "    if torch.cuda.is_available() and not options.cuda:\n",
    "        print(\"WARNING: You have a CUDA device, so you should probably run with --cuda\")\n",
    "\n",
    "    init_seed(options)\n",
    "    test_dataloader = init_dataset(options)[-1]\n",
    "    model = init_protonet(options)\n",
    "    model_path = os.path.join(opt.experiment_root, 'best_model.pth')\n",
    "    model.load_state_dict(torch.load(model_path))\n",
    "\n",
    "    test(opt=options,\n",
    "         test_dataloader=test_dataloader,\n",
    "         model=model)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "id": "q69hMyX_hgvC"
   },
   "outputs": [],
   "source": [
    "d = {\n",
    "    'experiment_root':'base_exp',\n",
    "     'epochs':200,\n",
    "     'test_epochs':20,\n",
    "    'iterations':50,\n",
    "     'cuda':True,\n",
    "     'classes_per_it_tr':10,\n",
    "    'lr_scheduler_step':20,\n",
    "    'num_query_tr':2,\n",
    "    'num_support_tr':2,\n",
    "         'num_query_val':2,\n",
    "     'num_support_val':2,\n",
    "    'learning_rate':0.0000000001,\n",
    "#      'check_point_path':'base_exp/best_after_blur_t48_val50.pth'\n",
    "     }\n",
    "options = get_parser().parse_args('')\n",
    "\n",
    "for key, value in d.items():\n",
    "        setattr(options, key, value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1e-10"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "options.learning_rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'E:\\\\CVprojects\\\\Butterflies\\\\split_dict_sub_main_clust.pkl'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "split_dict_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 8911/8911 [02:58<00:00, 49.93it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████| 4168/4168 [01:50<00:00, 37.77it/s]\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "Initialize everything and train\n",
    "'''\n",
    "# options = get_parser().parse_args()\n",
    "if not os.path.exists(options.experiment_root):\n",
    "    os.makedirs(options.experiment_root)\n",
    "\n",
    "if torch.cuda.is_available() and not options.cuda:\n",
    "    print(\"WARNING: You have a CUDA device, so you should probably run with --cuda\")\n",
    "\n",
    "init_seed(options)\n",
    "\n",
    "tr_dataloader = init_dataloader(options, 'train')\n",
    "val_dataloader = init_dataloader(options, 'val')\n",
    "# test_dataloader = init_dataloader(options, 'test')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "E:\\CVprojects\\Butterflies\\src\n"
     ]
    }
   ],
   "source": [
    "cd E:\\CVprojects\\Butterflies\\src"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from EncoderProtoNet import EncoderProtoNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = EncoderProtoNet(proto_x_dim=128)\n",
    "# model.load_state_dict(torch.load('E:\\\\CVprojects\\\\Butterflies\\\\src\\\\base_exp\\\\best_model_tr88_val87.pth'))\n",
    "\n",
    "\n",
    "enc_weights_path = 'E:\\\\CVprojects\\\\Butterflies\\\\base_exp\\\\best_model_embed_res.pth'\n",
    "model.load_encoder_weights(enc_weights_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.encoder.requires_gradient = False\n",
    "model = model.to('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "optim = init_optim(options, model)\n",
    "lr_scheduler = init_lr_scheduler(options, optim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "iVOF6u9Fgqzb",
    "outputId": "04ef0830-a864-47d3-e981-58f62d9b6e16",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Epoch: 0 ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 50/50 [00:26<00:00,  1.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg Train Loss: 0.43750980526208877, Avg Train Acc: 0.8500000011920928\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 50/50 [00:09<00:00,  5.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg Val Loss: 0.19818895254298696, Avg Val Acc: 0.9259999942779541 (Best)\n",
      "=== Epoch: 1 ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 50/50 [00:24<00:00,  2.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg Train Loss: 0.4695166964828968, Avg Train Acc: 0.8269999992847442\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 50/50 [00:08<00:00,  5.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg Val Loss: 0.21632231191149912, Avg Val Acc: 0.915999995470047 (Best: 0.9259999942779541)\n",
      "=== Epoch: 2 ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 50/50 [00:28<00:00,  1.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg Train Loss: 0.46294905960559846, Avg Train Acc: 0.8310000026226043\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 50/50 [00:10<00:00,  4.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg Val Loss: 0.30468057278194466, Avg Val Acc: 0.9099999976158142 (Best: 0.9259999942779541)\n",
      "=== Epoch: 3 ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 50/50 [00:37<00:00,  1.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg Train Loss: 0.510052755177021, Avg Train Acc: 0.8199999976158142\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 50/50 [00:04<00:00, 10.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg Val Loss: 0.149820673475042, Avg Val Acc: 0.9499999928474426 (Best)\n",
      "=== Epoch: 4 ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 50/50 [00:37<00:00,  1.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg Train Loss: 0.5021654780209065, Avg Train Acc: 0.8440000021457672\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 50/50 [00:04<00:00, 11.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg Val Loss: 0.2346070210589096, Avg Val Acc: 0.9119999969005584 (Best: 0.9499999928474426)\n",
      "=== Epoch: 5 ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 50/50 [00:31<00:00,  1.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg Train Loss: 0.4605772176384926, Avg Train Acc: 0.8369999980926514\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 50/50 [00:02<00:00, 19.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg Val Loss: 0.2625855750706978, Avg Val Acc: 0.9039999914169311 (Best: 0.9499999928474426)\n",
      "=== Epoch: 6 ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 50/50 [00:30<00:00,  1.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg Train Loss: 0.4756956531107426, Avg Train Acc: 0.8430000007152557\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 50/50 [00:03<00:00, 13.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg Val Loss: 0.18241852889070287, Avg Val Acc: 0.9419999933242797 (Best: 0.9499999928474426)\n",
      "=== Epoch: 7 ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 50/50 [00:29<00:00,  1.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg Train Loss: 0.4479148876667023, Avg Train Acc: 0.8440000021457672\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 50/50 [00:08<00:00,  6.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg Val Loss: 0.16041101879207417, Avg Val Acc: 0.9399999928474426 (Best: 0.9499999928474426)\n",
      "=== Epoch: 8 ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 50/50 [00:28<00:00,  1.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg Train Loss: 0.4556157518923283, Avg Train Acc: 0.8490000021457672\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 50/50 [00:09<00:00,  5.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg Val Loss: 0.24612290573124482, Avg Val Acc: 0.8999999964237213 (Best: 0.9499999928474426)\n",
      "=== Epoch: 9 ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 50/50 [00:26<00:00,  1.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg Train Loss: 0.46299097515642645, Avg Train Acc: 0.8450000011920928\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 50/50 [00:09<00:00,  5.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg Val Loss: 0.2591412639780901, Avg Val Acc: 0.8999999940395356 (Best: 0.9499999928474426)\n",
      "=== Epoch: 10 ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 50/50 [00:27<00:00,  1.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg Train Loss: 0.47921706780791284, Avg Train Acc: 0.8310000014305114\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 50/50 [00:09<00:00,  5.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg Val Loss: 0.19424731616396457, Avg Val Acc: 0.9259999930858612 (Best: 0.9499999928474426)\n",
      "=== Epoch: 11 ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 50/50 [00:26<00:00,  1.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg Train Loss: 0.473960784971714, Avg Train Acc: 0.844000004529953\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 50/50 [00:10<00:00,  4.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg Val Loss: 0.1653894588397816, Avg Val Acc: 0.92599999666214 (Best: 0.9499999928474426)\n",
      "=== Epoch: 12 ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 50/50 [00:27<00:00,  1.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg Train Loss: 0.5083422839641571, Avg Train Acc: 0.8149999988079071\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 50/50 [00:10<00:00,  4.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg Val Loss: 0.2522317611868493, Avg Val Acc: 0.9199999928474426 (Best: 0.9499999928474426)\n",
      "=== Epoch: 13 ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 50/50 [00:27<00:00,  1.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg Train Loss: 0.5388916596770287, Avg Train Acc: 0.8149999988079071\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 50/50 [00:10<00:00,  4.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg Val Loss: 0.2220466814842075, Avg Val Acc: 0.9219999933242797 (Best: 0.9499999928474426)\n",
      "=== Epoch: 14 ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 54%|████████████████████████████████████████████▎                                     | 27/50 [00:28<00:23,  1.04s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_17628\\756395412.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m             \u001b[0mmodel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m             \u001b[0moptim\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0moptim\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m             lr_scheduler=lr_scheduler)\n\u001b[0m\u001b[0;32m      7\u001b[0m \u001b[0mbest_state\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbest_acc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_loss\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_acc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mval_loss\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mval_acc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mres\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_17628\\369111801.py\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(opt, tr_dataloader, model, optim, lr_scheduler, val_dataloader)\u001b[0m\n\u001b[0;32m     29\u001b[0m             \u001b[0mmodel_output\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     30\u001b[0m             loss, acc = loss_fn(model_output, target=y,\n\u001b[1;32m---> 31\u001b[1;33m                                 n_support=opt.num_support_tr)\n\u001b[0m\u001b[0;32m     32\u001b[0m             \u001b[0mloss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     33\u001b[0m             \u001b[0moptim\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\CVprojects\\Butterflies\\Prototypical_Networks_for_Few_shot_Learning_PyTorch\\src\\prototypical_loss.py\u001b[0m in \u001b[0;36mprototypical_loss\u001b[1;34m(input, target, n_support)\u001b[0m\n\u001b[0;32m     51\u001b[0m       \u001b[0mbarycentres\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0meach\u001b[0m \u001b[0mone\u001b[0m \u001b[0mof\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mcurrent\u001b[0m \u001b[0mclasses\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     52\u001b[0m     '''\n\u001b[1;32m---> 53\u001b[1;33m     \u001b[0mtarget_cpu\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtarget\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'cpu'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     54\u001b[0m     \u001b[0minput_cpu\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'cpu'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     55\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "res = train(opt=options,\n",
    "            tr_dataloader=tr_dataloader,\n",
    "            val_dataloader=val_dataloader,\n",
    "            model=model,\n",
    "            optim=optim,\n",
    "            lr_scheduler=lr_scheduler)\n",
    "best_state, best_acc, train_loss, train_acc, val_loss, val_acc = res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load_state_dict(torch.load('base_exp/best_model_95val_82tr.pth'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.encoder.requires_gradient = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "b6ehYKK1y92P",
    "outputId": "6e7149f1-824e-46d0-ea76-5fa19c5d4754"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 4168/4168 [01:30<00:00, 46.24it/s]\n"
     ]
    }
   ],
   "source": [
    "test_dataloader = init_dataloader(options, 'test')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "c88cHxT-cS1B",
    "outputId": "70a13655-3eff-402e-f7f3-39d96b1acc71"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing with last model..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 20/20 [02:07<00:00,  6.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Acc: 0.9118999935984612\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9118999935984612"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('Testing with last model..')\n",
    "test(opt=options,\n",
    "      test_dataloader=test_dataloader,\n",
    "      model=model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4es1kBAwlfZl"
   },
   "outputs": [],
   "source": [
    "model.load_state_dict(best_state)\n",
    "print('Testing with best model..')\n",
    "test(opt=options,\n",
    "      test_dataloader=test_dataloader,\n",
    "      model=model)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "BaseExp.ipynb",
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
